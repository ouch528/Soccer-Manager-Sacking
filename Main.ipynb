{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc28b6a-8343-4070-9df3-36483ba0ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58309c9e-94e8-4819-8810-c2c808205d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv('REDDIT_CLIENT_ID')\n",
    "client_secret = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "user_agent = os.getenv('REDDIT_USER_AGENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=os.getenv('AWS_ACCESS_KEY_ID'),\n",
    "    aws_secret_access_key=os.getenv('AWS_SECRET_ACCESS_KEY'),\n",
    "    region_name=os.getenv('AWS_REGION')  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b87691a7-caa4-4714-a75c-5b911dd07633",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id= client_id,\n",
    "    client_secret= client_secret,\n",
    "    user_agent= user_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c1bbd-5fd9-4e6e-b591-d4a0d49bc80f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded to S3 successfully. Time taken: 8.63 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import boto3\n",
    "import praw  \n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def fetch_comments(submission):\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    return [\n",
    "        {\n",
    "            'comment': comment.body,\n",
    "            'score': comment.score,\n",
    "            'submission_title': submission.title,\n",
    "        }\n",
    "        for comment in submission.comments.list()\n",
    "    ]\n",
    "\n",
    "def collect_and_upload_comments(subreddit_name, search_query, csv_file_path, s3_bucket_name, s3_file_name, max_workers=10, limit=50, max_comments=100):\n",
    "    start_time = time.time()\n",
    "\n",
    "    comments_data = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(fetch_comments, submission)\n",
    "            for submission in reddit.subreddit(subreddit_name).search(search_query, sort='new', limit=limit)\n",
    "        ]\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            comments_data.extend(future.result())\n",
    "\n",
    "    comments_data = comments_data[:max_comments]\n",
    "\n",
    "    comments_df = pd.DataFrame(comments_data)\n",
    "\n",
    "    comments_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    s3.upload_file(csv_file_path, s3_bucket_name, s3_file_name)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Data uploaded to S3 successfully. Time taken: {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "collect_and_upload_comments(\n",
    "    subreddit_name=\"soccer\",\n",
    "    search_query=\"FC Barcelona\",\n",
    "    csv_file_path=\"barcelona_comments.csv\",\n",
    "    s3_bucket_name=\"reddit-football-text\",\n",
    "    s3_file_name=\"barca.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ada51-aa6a-414d-9826-35dd4b699d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentiment Score: 0.34\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "s3_bucket_name = 'reddit-football-text'\n",
    "s3_file_name = 'man_utd.csv'\n",
    "\n",
    "obj = s3.get_object(Bucket=s3_bucket_name, Key=s3_file_name)\n",
    "data = pd.read_csv(obj['Body'])\n",
    "\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\", truncation=True, max_length=512)\n",
    "\n",
    "def encode_sentiment(sentiment):\n",
    "    return 1 if sentiment == \"POSITIVE\" else 0\n",
    "\n",
    "batch_size = 10\n",
    "encoded_sentiments = []\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[\"comment\"][i:i + batch_size].tolist() \n",
    "    batch_results = sentiment_analysis(batch) \n",
    "\n",
    "    encoded_sentiments.extend([encode_sentiment(result['label']) for result in batch_results])\n",
    "\n",
    "average_sentiment = sum(encoded_sentiments) / len(encoded_sentiments)\n",
    "print(f\"Average Sentiment Score: {average_sentiment:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ScraperFC as sfc\n",
    "import pandas as pd\n",
    "\n",
    "ss = sfc.Sofascore()\n",
    "\n",
    "league_data = ss.get_match_dicts(\"23/24\", \"EPL\")\n",
    "\n",
    "processed_matches = []\n",
    "for match in league_data:\n",
    "    match_data = {\n",
    "        \"tournament_name\": match['tournament']['name'],\n",
    "        \"season_name\": match['season']['name'],\n",
    "        \"round\": match['roundInfo'].get('round', None),\n",
    "        \"status\": match['status']['description'],\n",
    "        \"winner_code\": match['winnerCode'],\n",
    "        \"home_team\": match['homeTeam']['name'],\n",
    "        \"away_team\": match['awayTeam']['name'],\n",
    "        \"home_score\": match['homeScore']['display'],\n",
    "        \"away_score\": match['awayScore']['display'],\n",
    "        \"injury_time_1\": match['time'].get('injuryTime1', 0),\n",
    "        \"injury_time_2\": match['time'].get('injuryTime2', 0),\n",
    "        \"start_timestamp\": match['startTimestamp'],\n",
    "        \"match_slug\": match['slug']\n",
    "    }\n",
    "    processed_matches.append(match_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "match_df = pd.DataFrame(processed_matches)\n",
    "match_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = sfc.FBref()\n",
    "season = ss.scrape_matches(\"2024-2025\", \"EPL\")\n",
    "season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d5e03e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Summary              Unnamed: 0_level_0 Unname...\n",
       "Name: Home Player Stats, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season.head(1)[\"Home Player Stats\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebba5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = sfc.FBref()\n",
    "match = fb.scrape_match('https://fbref.com/en/matches/67ed3ba2/Brentford-Tottenham-Hotspur-August-13-2023-Premier-League')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
